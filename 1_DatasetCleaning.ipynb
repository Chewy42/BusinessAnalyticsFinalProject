{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 7,
>>>>>>> f4a7e8213111786593d53e6dc0e07778d337027b
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mzip_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(zip_path)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset downloaded and extracted to ./datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/zipfile/__init__.py:1744\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/zipfile/__init__.py:1802\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[1;32m   1800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[1;32m   1801\u001b[0m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[0;32m-> 1802\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/shutil.py:204\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    202\u001b[0m fdst_write \u001b[38;5;241m=\u001b[39m fdst\u001b[38;5;241m.\u001b[39mwrite\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf \u001b[38;5;241m:=\u001b[39m fsrc_read(length):\n\u001b[0;32m--> 204\u001b[0m     \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# Downloads the dataset (~4gb) into a /datasets folder\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "os.makedirs('datasets', exist_ok=True)\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/googleai/regen-reviews-enhanced-with-generative-narratives\"\n",
    "\n",
    "regen_path = os.path.join('datasets', 'REGEN')\n",
    "if os.path.exists(regen_path):\n",
    "    print(\"REGEN folder found, please delete or rename the directory. If you already have the dataset, please ignore this message.\")\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        zip_path = os.path.join('datasets', 'archive.zip')\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('datasets')\n",
    "        \n",
    "        os.remove(zip_path)\n",
    "        print(\"Dataset downloaded and extracted to ./datasets\")\n",
    "    else:\n",
    "        print(f\"Failed to download. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/REGEN/clothing.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m                 f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample: No non-null values found\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    108\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 110\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mread_large_jsonl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/REGEN/clothing.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties.reviewer_id\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Export stats to file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36mread_large_jsonl\u001b[1;34m(file_path, lines)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_large_jsonl\u001b[39m(file_path, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f):\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m lines:\n",
      "File \u001b[1;32mc:\\Users\\mfave\\OneDrive\\Desktop\\BusinessAnalyticsFinalProject\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/REGEN/clothing.jsonl'"
     ]
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\('\n",
      "/var/folders/cv/03jvmtpn1gxf7kt2q73qzg180000gn/T/ipykernel_21254/44413067.py:49: SyntaxWarning: invalid escape sequence '\\('\n",
      "  mask = mask | df[col].astype(str).str.contains('\\(\\);', na=False)\n",
      "/var/folders/cv/03jvmtpn1gxf7kt2q73qzg180000gn/T/ipykernel_21254/44413067.py:49: SyntaxWarning: invalid escape sequence '\\('\n",
      "  mask = mask | df[col].astype(str).str.contains('\\(\\);', na=False)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/REGEN/clothing.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m                 f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample: No non-null values found\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 110\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mread_large_jsonl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/REGEN/clothing.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties.reviewer_id\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Export stats to file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mread_large_jsonl\u001b[0;34m(file_path, lines)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_large_jsonl\u001b[39m(file_path, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f):\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m lines:\n",
      "File \u001b[0;32m~/Documents/School/MGSC410/BusinessAnalyticsFinalProject/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/REGEN/clothing.jsonl'"
     ]
>>>>>>> f4a7e8213111786593d53e6dc0e07778d337027b
    }
   ],
   "source": [
    "def read_large_jsonl(file_path, lines=1000):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= lines:\n",
    "                break\n",
    "            json_obj = json.loads(line.strip())\n",
    "            \n",
    "            # Flatten purchase history into separate columns with dot notation\n",
    "            flattened = {}\n",
    "            \n",
    "            # Add base properties\n",
    "            flattened['properties.reviewer_id'] = json_obj.get('reviewer_id', np.nan)\n",
    "            \n",
    "            # Add purchase history\n",
    "            for idx, purchase in enumerate(json_obj['purchase_history']):\n",
    "                prefix = f'properties.purchase_history.{idx+1}.'\n",
    "                \n",
    "                # Item details\n",
    "                flattened[f'{prefix}item.asin'] = purchase['item'].get('asin', np.nan)\n",
    "                # Clean strings by replacing newlines, commas, and normalizing spaces\n",
    "                flattened[f'{prefix}item.title'] = ' '.join(''.join(char for char in purchase['item'].get('title', '') if char.isalnum() or char.isspace()).split()) or np.nan\n",
    "                flattened[f'{prefix}item.category'] = ' '.join(''.join(char for char in purchase['item'].get('category', '') if char.isalnum() or char.isspace()).split()) or np.nan\n",
    "                flattened[f'{prefix}item.description'] = ' '.join(''.join(char for char in purchase['item'].get('description', '') if char.isalnum() or char.isspace()).split()) if purchase['item'].get('description') else np.nan\n",
    "                flattened[f'{prefix}item.price'] = float(purchase['item'].get('price', np.nan))\n",
    "                \n",
    "                # Review details\n",
    "                flattened[f'{prefix}review.summary'] = ' '.join(''.join(char for char in purchase['review'].get('summary', '') if char.isalnum() or char.isspace()).split()) or np.nan\n",
    "                flattened[f'{prefix}review.rating'] = float(purchase['review'].get('rating', np.nan))\n",
    "                flattened[f'{prefix}review.text'] = ' '.join(''.join(char for char in purchase['review'].get('text', '') if char.isalnum() or char.isspace()).split()) or np.nan\n",
    "                flattened[f'{prefix}review.timestamp'] = float(purchase['review'].get('unix_time', np.nan))\n",
    "\n",
    "            # Add other fields with properties prefix\n",
    "            for k,v in json_obj.items():\n",
    "                if k != 'purchase_history' and k != 'reviewer_id':\n",
    "                    if isinstance(v, str):\n",
    "                        v = ' '.join(''.join(char for char in v if char.isalnum() or char.isspace()).split()) or np.nan\n",
    "                    elif isinstance(v, (int, float)):\n",
    "                        v = float(v)\n",
    "                    flattened[f'properties.{k}'] = v if v else np.nan\n",
    "            \n",
    "            data.append(pd.json_normalize(flattened))\n",
    "            \n",
    "    df = pd.concat(data, ignore_index=True)\n",
    "    \n",
    "    # Drop rows containing '();' in any string column\n",
    "    mask = pd.Series(False, index=df.index)\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        mask = mask | df[col].astype(str).str.contains('\\(\\);', na=False)\n",
    "    df = df[~mask]\n",
    "    \n",
    "    # Drop rows containing www, html, or javascript in any string column\n",
    "    banned_words = ['www', 'html', 'javascript']\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        for word in banned_words:\n",
    "            mask = mask | df[col].astype(str).str.contains(word, case=False, na=False)\n",
    "    df = df[~mask]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def export_dataframe_stats(df, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8', errors='replace') as f:\n",
    "        # Write shape\n",
    "        f.write(f\"Shape: {df.shape}\\n\\n\")\n",
    "        \n",
    "        # Write columns, 3 per line, keeping brackets\n",
    "        columns = list(df.columns)\n",
    "        f.write(\"[\\n\")\n",
    "        for i in range(0, len(columns), 3):\n",
    "            line = \"    \" + \", \".join([f\"'{col}'\" for col in columns[i:i+3]])\n",
    "            if i + 3 < len(columns):\n",
    "                line += \",\"\n",
    "            f.write(line + \"\\n\")\n",
    "        f.write(\"]\\n\\n\")\n",
    "        \n",
    "        # Write statistics in groups of 3 columns\n",
    "        f.write(\"Statistics:\\n\")\n",
    "        desc = df.describe()\n",
    "        pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "        \n",
    "        # Process 3 columns at a time\n",
    "        for i in range(0, len(desc.columns), 3):\n",
    "            subset_cols = desc.columns[i:i+3]\n",
    "            subset_desc = desc[subset_cols]\n",
    "            f.write(subset_desc.to_string())\n",
    "            f.write(\"\\n\\n\")\n",
    "            \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Write column info and first non-null examples\n",
    "        f.write(\"Column Examples:\\n\\n\")\n",
    "        for col in df.columns:\n",
    "            f.write(f\"{col}: {df[col].dtype}\\n\")\n",
    "            # Get first non-null value if exists\n",
    "            non_null_values = df[col].dropna()\n",
    "            if len(non_null_values) > 0:\n",
    "                first_value = non_null_values.iloc[0]\n",
    "                # Format the output nicely\n",
    "                if isinstance(first_value, (dict, list)):\n",
    "                    example = str(first_value)\n",
    "                elif isinstance(first_value, str):\n",
    "                    example = first_value\n",
    "                else:\n",
    "                    example = f\"{float(first_value):.1f}\"\n",
    "                f.write(f\"Example: {example}\\n\")\n",
    "            else:\n",
    "                f.write(\"Example: No non-null values found\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "df = read_large_jsonl(\"datasets/REGEN/clothing.jsonl\", lines=150000)\n",
    "df.drop(columns=['properties.reviewer_id'], inplace=True)\n",
    "\n",
    "# Export stats to file\n",
    "export_dataframe_stats(df, \"datasets/REGEN/clothing_described.txt\")\n",
    "df.to_csv(\"datasets/REGEN/clothing_cleaned.csv\", index=False)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(df.describe())\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
